{
    "title": "Lens Studio AR Pipeline",
    "image": "assets/blogs/blog-1.png",
    "content": "**How AR Content Flows in Lens Studio**\n\nThis is part one of the **Behind the Scenes of Lens Studio** series. A good first step in going behind the scenes is understanding how the whole show comes together from camera input to final frame.\n\nWhen I first started building lenses, I wished I had a single visual map of how everything actually moved through the pipeline—so I designed this diagram to show it clearly.\n\nThink of the AR pipeline like preparing a stage performance. Each department hands off to the next, shaping what the audience finally sees.\n\n**Camera Feed**\n\nThis is the raw stage—the RGB frames captured by the device. Sometimes there’s depth or infrared data, but the core is always the visual input.\n\n**Tracking System**\n\nThis is your choreography team. It analyzes each frame and identifies faces, hands, bodies, or surfaces, producing positions, rotations, key points, and masks.\n\n**Scene Update**\n\nHere’s where the actors start moving. Scripts control positioning, animation, interaction, and timed behaviors.\n\n**Effect Graph**\n\nThis is makeup, lighting, and special effects combined. Shaders, textures, blending, segmentation, particles—this is where the creative look is shaped.\n\n**Final Render**\n\nEverything comes together. The pipeline blends the camera feed, tracked data, scene updates, and visual effects into the final frame the user sees.\n\n**Why This Matters**\n\nHaving a deeper understanding of the AR pipeline can help with more advanced things like optimization down the line. It also sets the foundations for important concepts that builds upon this."
}
